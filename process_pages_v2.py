import os
import argparse
import base64
import json
import time
from io import BytesIO

from PIL import Image
from langchain_community.chat_models import ChatOllama
from langchain_core.messages import HumanMessage

# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®š ---
INPUT_DIR = "imgs"
OUTPUT_DIR = "outputs"
CACHE_DIR = "analysis_cache"
OLLAMA_MODEL = "llava"

# --- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®šç¾© ---

# 1. ãƒšãƒ¼ã‚¸æ§‹é€ ã‚’è§£æã•ã›ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ (ãƒ‘ã‚¹1)
ANALYSIS_PROMPT = """
Analyze the layout and structure of this page from the 'Homotopy Type Theory' book.
Identify key components such as headers, footers, main text columns, figures, captions, and complex mathematical formula blocks.
Describe any potential challenges for OCR, such as multi-column layouts, rotated text, unusual fonts, or dense mathematical notation.
Output your analysis as a concise list of observations in JSON format. Example: {"observations": ["Two-column layout", "Contains a complex diagram in the bottom-right", "Header contains page number"]}
"""

# 2. é€šå¸¸ã®æŠ½å‡ºãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ (ãƒ‘ã‚¹1)
BASIC_EXTRACTION_PROMPT = """
This image contains a page from the "Homotopy Type Theory: Univalent Foundations of Mathematics" book.
Please transcribe the content into a clean Markdown format.
Pay close attention to mathematical formulas and expressions, ensuring they are accurately represented, preferably using LaTeX syntax (e.g., $$ ... $$ or $ ... $).
Do not add any comments or explanations, only the transcribed Markdown content.
"""

# 3. è§£æçµæœã‚’ä»˜åŠ ã—ã¦é«˜ç²¾åº¦ãªæŠ½å‡ºã‚’è¡Œã†ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ (ãƒ‘ã‚¹2)
REFINED_EXTRACTION_PROMPT_TEMPLATE = """
This image contains a page from the "Homotopy Type Theory" book.
A preliminary analysis of this page revealed the following structural points:
--- ANALYSIS ---
{analysis_text}
--- END ANALYSIS ---
Considering this analysis, please perform a highly accurate transcription of the content into a clean Markdown format.
Pay extra close attention to mathematical formulas, expressions, and the overall structure described in the analysis.
Ensure formulas are correctly represented using LaTeX syntax ($$...$$ or $...$).
Do not add any comments, just the final Markdown content.
"""


def image_to_base64(image_path: str) -> str:
    """ç”»åƒã‚’Base64æ–‡å­—åˆ—ã«å¤‰æ›ã™ã‚‹"""
    try:
        with Image.open(image_path) as img:
            buffered = BytesIO()
            if img.mode in ('RGBA', 'P'):
                img = img.convert('RGB')
            img.save(buffered, format="JPEG")
            return base64.b64encode(buffered.getvalue()).decode('utf-8')
    except Exception as e:
        print(f"âŒ ç”»åƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {image_path}, {e}")
        return None

def call_llm(chat_model, prompt_text, b64_image):
    """LLMã‚’å‘¼ã³å‡ºã—ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å–å¾—ã™ã‚‹"""
    message = HumanMessage(
        content=[
            {"type": "text", "text": prompt_text},
            {"type": "image_url", "image_url": f"data:image/jpeg;base64,{b64_image}"},
        ]
    )
    try:
        response = chat_model.invoke([message])
        return response.content
    except Exception as e:
        print(f"âŒ Ollamaãƒ¢ãƒ‡ãƒ«å‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def analyze_page_structure(chat_model, image_path, cache_path):
    """ãƒšãƒ¼ã‚¸ã®æ§‹é€ ã‚’åˆ†æã™ã‚‹ (ãƒ‘ã‚¹1)"""
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒå­˜åœ¨ã™ã‚Œã°åˆ©ç”¨ã™ã‚‹
    if os.path.exists(cache_path):
        print(f"ğŸ§  ã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆ©ç”¨: {os.path.basename(cache_path)}")
        with open(cache_path, 'r', encoding='utf-8') as f:
            return json.load(f).get("analysis_text")

    print(f"ğŸ”¬ ãƒšãƒ¼ã‚¸æ§‹é€ ã‚’è§£æä¸­: {os.path.basename(image_path)}")
    b64_image = image_to_base64(image_path)
    if not b64_image: return None

    analysis_text = call_llm(chat_model, ANALYSIS_PROMPT, b64_image)
    if analysis_text:
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
        with open(cache_path, 'w', encoding='utf-8') as f:
            json.dump({"analysis_text": analysis_text}, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ è§£æçµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {os.path.basename(cache_path)}")
    return analysis_text

def run_basic_process(chat_model, files_to_process):
    """æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ç¾¤ã«åŸºæœ¬çš„ãª1ãƒ‘ã‚¹å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹"""
    print("\n--- ğŸš€ åŸºæœ¬å‡¦ç†ãƒ¢ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã™ ---")
    for filename in files_to_process:
        input_path = os.path.join(INPUT_DIR, filename)
        output_filename = os.path.splitext(filename)[0] + ".md"
        output_path = os.path.join(OUTPUT_DIR, output_filename)

        if os.path.exists(output_path):
            print(f"â© ã‚¹ã‚­ãƒƒãƒ—: {output_filename} ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚")
            continue

        print(f"ğŸ“„ åŸºæœ¬å‡¦ç†ä¸­: {filename}")
        b64_image = image_to_base64(input_path)
        if not b64_image: continue

        start_time = time.time()
        markdown_content = call_llm(chat_model, BASIC_EXTRACTION_PROMPT, b64_image)
        if markdown_content:
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(markdown_content)
            processing_time = time.time() - start_time
            print(f"âœ… æˆåŠŸ: {output_filename} ã‚’ä½œæˆã—ã¾ã—ãŸã€‚({processing_time:.2f}ç§’)")

def run_refine_process(chat_model, refine_files):
    """æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ç¾¤ã«é«˜ç²¾åº¦ãª2ãƒ‘ã‚¹å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹"""
    print("\n--- âœ¨ å†å‡¦ç†ï¼ˆãƒªãƒ•ã‚¡ã‚¤ãƒ³ï¼‰ãƒ¢ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã™ ---")
    for filename in refine_files:
        print(f"\n--- ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ: {filename} ---")
        input_path = os.path.join(INPUT_DIR, filename)
        output_filename = os.path.splitext(filename)[0] + ".md"
        output_path = os.path.join(OUTPUT_DIR, output_filename)
        cache_filename = os.path.splitext(filename)[0] + ".json"
        cache_path = os.path.join(CACHE_DIR, cache_filename)

        # ãƒ‘ã‚¹1: ãƒšãƒ¼ã‚¸æ§‹é€ ã®è§£æ
        analysis_text = analyze_page_structure(chat_model, input_path, cache_path)
        if not analysis_text:
            print(f"âŒ è§£æå¤±æ•—: {filename}")
            continue

        # ãƒ‘ã‚¹2: è§£æçµæœã‚’åˆ©ç”¨ã—ãŸé«˜ç²¾åº¦æŠ½å‡º
        print(f"âœï¸ é«˜ç²¾åº¦æŠ½å‡ºã‚’å®Ÿè¡Œä¸­: {filename}")
        b64_image = image_to_base64(input_path)
        if not b64_image: continue

        start_time = time.time()
        final_prompt = REFINED_EXTRACTION_PROMPT_TEMPLATE.format(analysis_text=analysis_text)
        markdown_content = call_llm(chat_model, final_prompt, b64_image)
        if markdown_content:
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(markdown_content)
            processing_time = time.time() - start_time
            print(f"âœ…âœ… æˆåŠŸ (å†å‡¦ç†): {output_filename} ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚({processing_time:.2f}ç§’)")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    for dir_path in [OUTPUT_DIR, CACHE_DIR]:
        if not os.path.exists(dir_path):
            os.makedirs(dir_path)

    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®è¨­å®š
    parser = argparse.ArgumentParser(description="HoTT Bookã®ãƒšãƒ¼ã‚¸ã‚’OCRå‡¦ç†ã—ã€Markdownã«å¤‰æ›ã—ã¾ã™ã€‚")
    parser.add_argument(
        '--refine',
        nargs='+',
        metavar='FILENAME',
        help="æŒ‡å®šã—ãŸãƒ•ã‚¡ã‚¤ãƒ«åã«å¯¾ã—ã¦é«˜ç²¾åº¦ãªå†å‡¦ç†ï¼ˆãƒªãƒ•ã‚¡ã‚¤ãƒ³ï¼‰ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚ä¾‹: --refine page-005.jpg page-012.jpg"
    )
    args = parser.parse_args()

    print(f"ğŸ¤– Ollama ({OLLAMA_MODEL}ãƒ¢ãƒ‡ãƒ«) ã‚’åˆæœŸåŒ–ã—ã¾ã™...")
    try:
        # temperatureã‚’ä½ã‚ã«è¨­å®šã—ã€ã‚ˆã‚Šå¿ å®Ÿãªå‡ºåŠ›ã‚’ä¿ƒã™
        chat = ChatOllama(model=OLLAMA_MODEL, temperature=0.1)
    except Exception as e:
        print(f"âŒ Ollamaãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: {e}")
        return

    if args.refine:
        run_refine_process(chat, args.refine)
    else:
        try:
            all_files = sorted([f for f in os.listdir(INPUT_DIR) if f.startswith("page-") and f.lower().endswith(".jpg")])
            run_basic_process(chat, all_files)
        except FileNotFoundError:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{INPUT_DIR}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return

    print("\n--- ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ ---")


if __name__ == "__main__":
    main()
