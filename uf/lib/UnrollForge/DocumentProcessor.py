from typing import Dict, Any, Tuple, List, Optional
from re import findall, MULTILINE
from .FileManager import FileManager
from .Log import Logger
from .LLMClient import LLMClient
from os import path

SYSTEM_PROMPT = """
You are an expert digital archivist specializing in mathematical and scientific texts. Your task is to perform high-fidelity Optical Character Recognition (OCR) and document layout analysis, converting physical pages into perfectly structured Markdown documents with accurate LaTeX formatting.
"""
BASIC_PROMPT = """{}\n{}\n
Your task is to transcribe the provided page into a clean Markdown document with perfect LaTeX formatting.\n
Here is an example of the quality and format require:\n
--- EXAMPLE START ---\n
{}\n
--- EXAMPLE END ---\n
"""

PERFECT_EXAMPLE_MARKDOWN = """
### Example Inline Mathematical Formula

This is an example of an inline mathematical formula: $E=mc^2$.

### Exapmle Block Mathematical Formula

This is an example of a block mathematical formula:
```math
\int_0^1 x^2 \, dx = \frac{1}{3}
```

### Example of a Table Content

| Header 1 | Header 2 | Header 3 |
|----------|----------|----------|
| Row 1 Col 1 | Row 1 Col 2 | Row 1 Col 3 |
| Row 2 Col 1 | Row 2 Col 2 | Row 2 Col 3 |

### Example of a Figure Caption
![Example Figure](placeholder.png)

**This is a placeholder for an image caption. The actual image will be processed and inserted later.**
"""

# --- 4. DocumentState ã‚¯ãƒ©ã‚¹ ---
class DocumentState:
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå…¨ä½“ã®å‡¦ç†çŠ¶æ…‹ã¨æ§‹é€ çš„æ–‡è„ˆï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼‰ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚"""
    def __init__(self, state_file_path: str, file_manager: FileManager, logger: Logger):
        self.state_file_path = state_file_path; self.file_manager = file_manager; self.logger = logger
        self._state: Dict[str, Any] = self._get_default_state(); self.load()
    def _get_default_state(self) -> Dict[str, Any]: return {"last_processed_page": None, "heading_context_stack": []}
    def load(self):
        self.logger.info(f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆçŠ¶æ…‹ã‚’ '{self.state_file_path}' ã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã™ã€‚")
        loaded_state = self.file_manager.read_json(self.state_file_path)
        if loaded_state and "last_processed_page" in loaded_state and "heading_context_stack" in loaded_state:
            self._state = loaded_state; self.logger.success("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆçŠ¶æ…‹ã®èª­ã¿è¾¼ã¿ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
        else:
            self.logger.info("æ—¢å­˜ã®çŠ¶æ…‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹å½¢å¼ãŒä¸æ­£ãªãŸã‚ã€æ–°ã—ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨ã—ã¦é–‹å§‹ã—ã¾ã™ã€‚"); self._state = self._get_default_state()
    def save(self):
        self.logger.info(f"ç¾åœ¨ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆçŠ¶æ…‹ã‚’ '{self.state_file_path}' ã«ä¿å­˜ã—ã¾ã™ã€‚")
        self.file_manager.write_json(self.state_file_path, self._state)
    def update_heading_stack(self, markdown_content: str):
        stack = self._state.get("heading_context_stack", []); headings = findall(r'^(#+)\s+(.*)', markdown_content, MULTILINE)
        if not headings: self.logger.info("ã“ã®ãƒšãƒ¼ã‚¸ã«ã¯æ–°ã—ã„è¦‹å‡ºã—ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¯å¤‰æ›´ã•ã‚Œã¾ã›ã‚“ã€‚"); return
        for heading_marks, title in headings:
            level = len(heading_marks); new_heading = {"level": level, "title": title.strip()}
            while stack and stack[-1]['level'] >= level: stack.pop()
            stack.append(new_heading)
        self._state["heading_context_stack"] = stack; self.logger.success(f"è¦‹å‡ºã—ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚")
    def get_context_prompt(self) -> Tuple[str, int]:
        stack = self._state.get("heading_context_stack", [])
        if not stack: context_str = "No current context (This is likely the beginning of the document)."; depth = 0
        else: path_str = " > ".join([f"{'#' * h['level']} {h['title']}" for h in stack]); depth = stack[-1]['level']; context_str = f"Current Path: {path_str}\nCurrent Heading Depth: {depth}"
        return f"\n--- DOCUMENT CONTEXT ---\n...\n{context_str}\n--- END DOCUMENT CONTEXT ---\n", depth
    def get_last_processed_page(self) -> Optional[str]: return self._state.get("last_processed_page")
    def set_last_processed_page(self, filename: str): self.logger.info(f"å‡¦ç†æ¸ˆã¿ãƒšãƒ¼ã‚¸ã‚’ '{filename}' ã«æ›´æ–°ã—ã¾ã—ãŸã€‚"); self._state["last_processed_page"] = filename

# --- 5. DocumentProcessor ã‚¯ãƒ©ã‚¹ (ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼) ---
class DocumentProcessor:
    """å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’å”èª¿ã•ã›ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å…¨ä½“ã‚’åˆ¶å¾¡ã™ã‚‹ã€‚"""
    
    PERFECT_EXAMPLE_MARKDOWN = """
...as shown in the equation:

$$ \sum_{i=0}^{n} i = \frac{n(n+1)}{2} $$

This is followed by more text.
"""

    def __init__(self, file_manager: FileManager, logger: Logger, llm_client: LLMClient, doc_state: DocumentState):
        self.file_manager = file_manager
        self.logger = logger
        self.llm_client = llm_client
        self.doc_state = doc_state

    def _analyze_page_structure(self, filename: str, context_prompt: str) -> Optional[str]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åˆ©ç”¨ã—ã¤ã¤ã€ãƒšãƒ¼ã‚¸ã®æ§‹é€ ã‚’LLMã§è§£æã™ã‚‹ (ãƒªãƒ•ã‚¡ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰ç”¨)ã€‚"""
        cache_path = self.file_manager.get_cache_path(filename)
        cached_data = self.file_manager.read_json(cache_path)
        if cached_data and "analysis_text" in cached_data:
            self.logger.success(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆ©ç”¨: {path.basename(cache_path)}")
            return cached_data["analysis_text"]

        self.logger.info(f"ãƒšãƒ¼ã‚¸æ§‹é€ ã‚’è§£æä¸­: {filename}")
        b64_image = self.file_manager.read_image_as_base64(filename)
        if not b64_image: return None

        analysis_prompt = f"""
        {SYSTEM_PROMPT}
        {context_prompt}
        Analyze the layout of this page by following these steps: 
        1. **Overall Layout**: First, identify the overall layout. Is it single-column, two-colmun, or something more complex?
        2. **Component Identification**: Second, locate and identify all distinct components: headers, footers, main text body, figures, tables, and most importantly, mathematical formula blocks.
        3. **Challenge Assessment**: Third, note any potential challenges for transcription, such as small font sizes, comples nested formulas, or unusual text flow.
        Provide your analysis as a concise JSON object, forcusing only on the structural facts.
"""
        analysis_text = self.llm_client.invoke(analysis_prompt, b64_image)

        if analysis_text:
            self.file_manager.write_json(cache_path, {"analysis_text": analysis_text})
        return analysis_text

    def run_basic(self):
        """æœªå‡¦ç†ã®å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¯¾è±¡ã«ã€åŸºæœ¬çš„ãªOCRå‡¦ç†ã‚’é †æ¬¡å®Ÿè¡Œã™ã‚‹ã€‚"""
        self.logger.start_section("ğŸš€ åŸºæœ¬å‡¦ç†ãƒ¢ãƒ¼ãƒ‰ é–‹å§‹")
        all_files = self.file_manager.get_image_files()
        last_processed = self.doc_state.get_last_processed_page()
        start_index = all_files.index(last_processed) + 1 if last_processed in all_files else 0
        if start_index > 0: self.logger.info(f"å‰å›ã®å‡¦ç† '{last_processed}' ã®æ¬¡ã‹ã‚‰å†é–‹ã—ã¾ã™ã€‚")

        files_to_run = all_files[start_index:]
        if not files_to_run: self.logger.success("ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯æ—¢ã«å‡¦ç†æ¸ˆã¿ã§ã™ã€‚"); return

        for filename in files_to_run:
            self.logger.start_section(f"ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ: {filename}")
            context_prompt, _ = self.doc_state.get_context_prompt()
            basic_prompt = BASIC_PROMPT.format(SYSTEM_PROMPT, context_prompt, self.PERFECT_EXAMPLE_MARKDOWN)

            b64_image = self.file_manager.read_image_as_base64(filename)
            if not b64_image: continue

            markdown_content = self.llm_client.invoke(basic_prompt, b64_image)
            if markdown_content:
                self.file_manager.write_markdown(filename, markdown_content)
                self.doc_state.update_heading_stack(markdown_content)
                self.doc_state.set_last_processed_page(filename)
                self.doc_state.save()
            else:
                self.logger.error(f"å‡¦ç†å¤±æ•—: {filename}ã€‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚"); break

    def run_refine(self, refine_files: List[str]):
        """æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã«å¯¾ã—ã¦ã€é«˜ç²¾åº¦ãªå†å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹ã€‚"""
        self.logger.start_section("âœ¨ å†å‡¦ç†ï¼ˆãƒªãƒ•ã‚¡ã‚¤ãƒ³ï¼‰ãƒ¢ãƒ¼ãƒ‰ é–‹å§‹")
        self.logger.warn("ã“ã®ãƒ¢ãƒ¼ãƒ‰ã¯æ–‡æ›¸å…¨ä½“ã®çŠ¶æ…‹ï¼ˆæœ€çµ‚å‡¦ç†ãƒšãƒ¼ã‚¸ãªã©ï¼‰ã‚’æ›´æ–°ã—ã¾ã›ã‚“ã€‚")

        for filename in refine_files:
            self.logger.start_section(f"ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ: {filename}")
            context_prompt, _ = self.doc_state.get_context_prompt()

            analysis_text = self._analyze_page_structure(filename, context_prompt)
            if not analysis_text: self.logger.error(f"è§£æå¤±æ•—: {filename}"); continue

            b64_image = self.file_manager.read_image_as_base64(filename)
            if not b64_image: continue

            refined_prompt = f"""{SYSTEM_PROMPT}
{context_prompt}
You will perform a highly accurate transcription of the provided page.
First, study this example:
--- EXAMPLE START ---
{PERFECT_EXAMPLE_MARKDOWN}
--- END EXAMPLE ---
Next, study this analysis:
--- ANALYSIS ---
{{analysis_text}}
--- END ANALYSIS ---
Considering both, transcribe the entire page.
"""

            markdown_content = self.llm_client.invoke(refined_prompt, b64_image)
            if markdown_content:
                self.file_manager.write_markdown(filename, markdown_content)
