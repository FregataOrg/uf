import os
import json
import base64
import time
from io import BytesIO
from PIL import Image

# LangChainã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from langchain_community.chat_models import ChatOllama
from langchain_core.messages import HumanMessage

# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®š ---
# ãƒ•ã‚§ãƒ¼ã‚º1ç”¨VLLM (è¦–è¦šã¨è¨€èª)
VLLM_MODEL = "qwen-vl" 
# ãƒ•ã‚§ãƒ¼ã‚º2ç”¨é«˜æ¬¡LLM (è«–ç†çš„æ¨è«–)
# â˜…â˜…â˜… ã“ã“ã«å†çµåˆç”¨ã®é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ (ä¾‹: 'llama3:70b', 'qwen2:72b') â˜…â˜…â˜…
REASSEMBLY_LLM_MODEL = "qwen2"

# --- ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š ---
INPUT_DIR = "imgs"
OUTPUT_DIR = "output"
LAYOUT_CACHE_DIR = "layout_cache"
TEMP_FIGURES_DIR = "temp_figures"

# --- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®šç¾© ---

# (ãƒ•ã‚§ãƒ¼ã‚º1) 1. ãƒšãƒ¼ã‚¸å…¨ä½“ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’è§£æã•ã›ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
LAYOUT_ANALYSIS_PROMPT = """
You are an expert document layout analyzer. Your task is to analyze the provided image of a page from a scientific book.
Identify all distinct logical components on the page. For each component, provide its type and its precise bounding box coordinates `[x_min, y_min, x_max, y_max]`.
Also, determine the primary language of the document.
The component types should be one of the following: `text_block`, `formula_block`, `figure`, `caption`, `header`, `footer`.
Your output MUST be a single, valid JSON object following this exact schema. Do not add any other text or explanations.
JSON_OUTPUT_EXAMPLE:
```json
{
  "language": "english",
  "components": [
    {"type": "header", "box": [50, 50, 950, 100]},
    {"type": "text_block", "box": [100, 120, 900, 500]},
    {"type": "figure", "box": [200, 520, 800, 800]}
  ]
}
```
"""

# (ãƒ•ã‚§ãƒ¼ã‚º1) 2. ãƒˆãƒªãƒŸãƒ³ã‚°ã•ã‚ŒãŸå€‹åˆ¥ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’OCRã™ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
COMPONENT_OCR_PROMPT = """
You are a highly specialized OCR engine. You will be given a small, pre-cropped image of a single document component.
Transcribe the content of this image with maximum accuracy.
- For text, output the plain text.
- For mathematical formulas, use proper LaTeX syntax.
Your output should be ONLY the transcribed content, with no extra explanations.
"""

# (ãƒ•ã‚§ãƒ¼ã‚º2) 3. ãƒãƒ©ãƒãƒ©ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’è«–ç†çš„ã«å†çµåˆã•ã›ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
REASSEMBLY_PROMPT_TEMPLATE = """
You are an expert technical editor. Your task is to reconstruct a page from a scientific document using a list of disordered content components.

### CONTEXT
- The document language is: **{language}**
- The standard reading direction is: **{reading_direction}** (This is a general rule, but logical connection is more important).

### INPUT DATA (List of Document Components)
Here are all the components extracted from the page in JSON format. Each component has an ID, type, bounding box (a hint for position), and its transcribed content.
```json
{components_json}
```

### YOUR TASK
1.  Analyze the `content` of all components to understand their logical relationships.
2.  Determine the most natural reading order that forms a coherent, logical flow.
3.  **PRIORITIZE SEMANTIC CONNECTION OVER POSITION.** For example, a sentence fragment in one block should be followed by its continuation in another, regardless of their `box` coordinates. A figure's caption should follow the figure or its reference.
4.  Your final output MUST be a single JSON array containing the component `id`s in the correct logical order.

### OUTPUT FORMAT EXAMPLE
`["comp_01", "comp_03", "comp_02", "comp_05", "comp_04"]`
"""

# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° (å¤‰æ›´ãªã—) ---
def setup_directories():
    for dir_path in [OUTPUT_DIR, LAYOUT_CACHE_DIR, TEMP_FIGURES_DIR]:
        os.makedirs(dir_path, exist_ok=True)

def image_to_base64(pil_image: Image.Image) -> str:
    buffered = BytesIO()
    pil_image.save(buffered, format="JPEG")
    return base64.b64encode(buffered.getvalue()).decode('utf-8')

def call_llm(model, prompt_text, b64_image=None):
    """LLM/VLLMã‚’å‘¼ã³å‡ºã—ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å–å¾—ã™ã‚‹ (ç”»åƒã¯ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«)"""
    content_list = [{"type": "text", "text": prompt_text}]
    if b64_image:
        content_list.append({"type": "image_url", "image_url": f"data:image/jpeg;base64,{b64_image}"})
    
    message = HumanMessage(content=content_list)
    try:
        response = model.invoke([message])
        content = response.content
        # ```json ... ``` ã®ã‚ˆã†ãªãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ–ãƒ­ãƒƒã‚¯ã‹ã‚‰JSONã‚’æŠ½å‡ºã™ã‚‹
        if "```json" in content:
            return content.split("```json")[1].split("```")[0].strip()
        # `[` ã§å§‹ã¾ã‚‹JSONé…åˆ—ã‚’ç›´æ¥æ¢ã™
        if content.strip().startswith("["):
            return content.strip()
        return content
    except Exception as e:
        print(f"âŒ LLM/VLLMãƒ¢ãƒ‡ãƒ«å‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def get_reading_direction(language: str) -> str:
    if language.lower() in ["japanese", "chinese"]: return "TBRL"
    return "LRTB"

# --- ãƒ•ã‚§ãƒ¼ã‚º1: ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè§£æã¨å€‹åˆ¥OCR (å¤‰æ›´ãªã—) ---
def analyze_and_extract_components(vllm_model, image_path: str):
    filename = os.path.basename(image_path)
    base_filename = os.path.splitext(filename)[0]
    layout_cache_path = os.path.join(LAYOUT_CACHE_DIR, f"{base_filename}_layout.json")
    try:
        full_image = Image.open(image_path).convert("RGB")
    except FileNotFoundError: return None
    layout_data = None
    if os.path.exists(layout_cache_path):
        with open(layout_cache_path, 'r', encoding='utf-8') as f: layout_data = json.load(f)
    else:
        full_image_b64 = image_to_base64(full_image)
        json_str = call_llm(vllm_model, LAYOUT_ANALYSIS_PROMPT, full_image_b64)
        if json_str:
            try:
                layout_data = json.loads(json_str)
                with open(layout_cache_path, 'w', encoding='utf-8') as f: json.dump(layout_data, f, indent=2)
            except json.JSONDecodeError: return None
    if not layout_data or 'components' not in layout_data: return None
    
    processed_components = []
    for idx, comp in enumerate(layout_data['components']):
        comp_id = f"comp_{idx+1:02d}"; comp_type = comp.get('type', 'unknown'); box = tuple(comp.get('box', []))
        if not box or len(box) != 4: continue
        cropped_img = full_image.crop(box)
        content = ""
        if comp_type == 'figure':
            temp_fig_dir = os.path.join(TEMP_FIGURES_DIR, base_filename)
            os.makedirs(temp_fig_dir, exist_ok=True)
            temp_fig_path = os.path.join(temp_fig_dir, f"{comp_id}.jpg")
            cropped_img.save(temp_fig_path); content = f"![{comp_type} {comp_id}]({os.path.relpath(temp_fig_path)})"
        else:
            content = call_llm(vllm_model, COMPONENT_OCR_PROMPT, image_to_base64(cropped_img)) or "[OCR FAILED]"
        processed_components.append({"id": comp_id, "type": comp_type, "box": list(box), "content": content})
        time.sleep(0.5)
    
    language = layout_data.get('language', 'unknown')
    return {"source_file": filename, "language": language, "reading_direction": get_reading_direction(language), "components": processed_components}

# --- ãƒ•ã‚§ãƒ¼ã‚º2: ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆå†çµåˆ (æ–°è¦è¿½åŠ ) ---
def reassemble_components(reassembly_llm, page_data: dict) -> str:
    """
    ã€ãƒ•ã‚§ãƒ¼ã‚º2ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°ã€‘
    é«˜æ¬¡LLMã‚’ä½¿ã£ã¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’è«–ç†çš„ã«ä¸¦ã¹æ›¿ãˆã€æœ€çµ‚çš„ãªMarkdownã‚’ç”Ÿæˆã™ã‚‹
    """
    print("\nğŸ”¬ 3. ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆå†çµåˆã‚’é–‹å§‹ã—ã¾ã™...")
    
    # LLMã«æ¸¡ã™ãŸã‚ã«ã€contentä»¥å¤–ã®ä¸è¦ãªã‚­ãƒ¼ã‚’ä¸€æ™‚çš„ã«å‰Šé™¤ã—ãŸã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãƒªã‚¹ãƒˆã‚’ä½œæˆ
    components_for_prompt = [{"id": c["id"], "type": c["type"], "box": c["box"], "content": c["content"]} for c in page_data["components"]]
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’çµ„ã¿ç«‹ã¦
    prompt = REASSEMBLY_PROMPT_TEMPLATE.format(
        language=page_data['language'],
        reading_direction=page_data['reading_direction'],
        components_json=json.dumps(components_for_prompt, indent=2)
    )
    
    # é«˜æ¬¡LLMã‚’å‘¼ã³å‡ºã—
    response_str = call_llm(reassembly_llm, prompt)
    
    if not response_str:
        print("âŒ å†çµåˆLLMã‹ã‚‰ã®å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return None
    
    try:
        # LLMã‹ã‚‰ã®å¿œç­”(IDã®JSONé…åˆ—)ã‚’ãƒ‘ãƒ¼ã‚¹
        ordered_ids = json.loads(response_str)
        print(f"âœ… LLMã«ã‚ˆã‚‹é †åºæ±ºå®š: {ordered_ids}")
    except json.JSONDecodeError:
        print(f"âŒ å†çµåˆLLMã®å¿œç­”JSONã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        print(f"   å—ä¿¡ã—ãŸæ–‡å­—åˆ—: {response_str}")
        return None
    
    # å…ƒã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’IDã§æ¤œç´¢ã§ãã‚‹ã‚ˆã†ã«è¾æ›¸ã«å¤‰æ›
    components_map = {c['id']: c for c in page_data['components']}
    
    # æ±ºå®šã•ã‚ŒãŸé †åºã§contentã‚’çµåˆ
    final_markdown_parts = []
    for comp_id in ordered_ids:
        if comp_id in components_map:
            final_markdown_parts.append(components_map[comp_id]['content'])
        else:
            print(f"âš ï¸ è­¦å‘Š: LLMãŒæœªçŸ¥ã®ID '{comp_id}' ã‚’è¿”ã—ã¾ã—ãŸã€‚")

    return "\n\n".join(final_markdown_parts)

if __name__ == '__main__':
    setup_directories()
    
    TEST_IMAGE_FILENAME = "page-003.jpg" # ãƒ†ã‚¹ãƒˆã—ãŸã„ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å
    test_image_path = os.path.join(INPUT_DIR, TEST_IMAGE_FILENAME)
    base_filename = os.path.splitext(TEST_IMAGE_FILENAME)[0]
    
    print("ğŸ¤– ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã—ã¾ã™...")
    try:
        vllm = ChatOllama(model=VLLM_MODEL, temperature=0.05)
        reassembly_llm = ChatOllama(model=REASSEMBLY_LLM_MODEL, temperature=0.0) # å†çµåˆã¯æ±ºå®šçš„ãªæ–¹ãŒè‰¯ã„
    except Exception as e:
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"); exit()
        
    # --- ãƒ•ã‚§ãƒ¼ã‚º1å®Ÿè¡Œ ---
    structured_data = analyze_and_extract_components(vllm, test_image_path)
    if not structured_data:
        print("ãƒ•ã‚§ãƒ¼ã‚º1ã§å‡¦ç†ãŒåœæ­¢ã—ã¾ã—ãŸã€‚"); exit()
        
    structured_data_path = os.path.join(OUTPUT_DIR, f"{base_filename}_structured.json")
    with open(structured_data_path, 'w', encoding='utf-8') as f:
        json.dump(structured_data, f, indent=2, ensure_ascii=False)
    print(f"\nâœ… ãƒ•ã‚§ãƒ¼ã‚º1å®Œäº†ã€‚ä¸­é–“ãƒ‡ãƒ¼ã‚¿ã‚’ {structured_data_path} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")

    # --- ãƒ•ã‚§ãƒ¼ã‚º2å®Ÿè¡Œ ---
    final_markdown = reassemble_components(reassembly_llm, structured_data)

    if final_markdown:
        final_md_path = os.path.join(OUTPUT_DIR, f"{base_filename}_final.md")
        with open(final_md_path, 'w', encoding='utf-8') as f:
            f.write(final_markdown)
        print(f"\nğŸ‰ å…¨å·¥ç¨‹å®Œäº†ï¼æœ€çµ‚çš„ãªMarkdownã‚’ {final_md_path} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
    else:
        print("\nâŒ ãƒ•ã‚§ãƒ¼ã‚º2ã§å‡¦ç†ãŒå¤±æ•—ã—ã¾ã—ãŸã€‚")
