import os
import argparse
import base64
import json
import time
import re
from io import BytesIO

from PIL import Image
from langchain_community.chat_models import ChatOllama
from langchain_core.messages import HumanMessage

# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®š ---
INPUT_DIR = "trim_imgs"
OUTPUT_DIR = "outputs_v2"
CACHE_DIR = "analysis_cache"
OLLAMA_MODEL = "qwen2.5vl:32b"
# â˜…â˜…â˜… çŠ¶æ…‹ç®¡ç†ãƒ•ã‚¡ã‚¤ãƒ« â˜…â˜…â˜…
STRUCTURE_FILE = "document_structure.json"


# --- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå®šç¾© ---
# ã“ã‚Œã‚‰ã¯å¾Œã»ã©å‹•çš„ã«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä»˜åŠ ã™ã‚‹ãŸã‚ã®ã€Œå…ƒã€ã¨ãªã‚Šã¾ã™

SYSTEM_PROMPT = """
You are an expert digital archivist specializing in mathematical and scientific texts. Your task is to perform high-fidelity Optical Character Recognition (OCR) and document layout analysis, converting physical pages into perfectly structured Markdown documents with accurate LaTeX formatting.
"""

PERFECT_EXAMPLE_MARKDOWN = """
...as shown in the equation:

$$ \sum_{i=0}^{n} i = \frac{n(n+1)}{2} $$

This is followed by more text.
"""

# --- çŠ¶æ…‹ç®¡ç†ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---

def load_document_state():
    """æ–‡æ›¸æ§‹é€ ã®çŠ¶æ…‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ã€‚ãªã‘ã‚Œã°åˆæœŸçŠ¶æ…‹ã‚’è¿”ã™ã€‚"""
    if not os.path.exists(STRUCTURE_FILE):
        print("ğŸ“– çŠ¶æ…‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€æ–°ã—ã„æ–‡æ›¸ã¨ã—ã¦é–‹å§‹ã—ã¾ã™ã€‚")
        return {"last_processed_page": None, "heading_context_stack": []}
    try:
        with open(STRUCTURE_FILE, 'r', encoding='utf-8') as f:
            print(f"ğŸ“– çŠ¶æ…‹ãƒ•ã‚¡ã‚¤ãƒ« '{STRUCTURE_FILE}' ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
            return json.load(f)
    except (json.JSONDecodeError, IOError) as e:
        print(f"âš ï¸ çŠ¶æ…‹ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}ã€‚åˆæœŸçŠ¶æ…‹ã‹ã‚‰é–‹å§‹ã—ã¾ã™ã€‚")
        return {"last_processed_page": None, "heading_context_stack": []}

def save_document_state(state):
    """ç¾åœ¨ã®æ–‡æ›¸æ§‹é€ ã®çŠ¶æ…‹ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹ã€‚"""
    try:
        with open(STRUCTURE_FILE, 'w', encoding='utf-8') as f:
            json.dump(state, f, indent=2, ensure_ascii=False)
    except IOError as e:
        print(f"âŒ çŠ¶æ…‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

def update_heading_stack(stack, markdown_content):
    """ç”Ÿæˆã•ã‚ŒãŸMarkdownã‚’è§£æã—ã€è¦‹å‡ºã—ã‚¹ã‚¿ãƒƒã‚¯ã‚’æ›´æ–°ã™ã‚‹ã€‚"""
    headings = re.findall(r'^(#+)\s+(.*)', markdown_content, re.MULTILINE)
    if not headings:
        return stack

    for heading_marks, title in headings:
        level = len(heading_marks)
        new_heading = {"level": level, "title": title.strip()}
        while stack and stack[-1]['level'] >= level:
            stack.pop()
        stack.append(new_heading)

    print(f"ğŸ“š è¦‹å‡ºã—ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ›´æ–°: ç¾åœ¨åœ° -> {format_context_for_prompt(stack)[0]}")
    return stack

def format_context_for_prompt(stack):
    """è¦‹å‡ºã—ã‚¹ã‚¿ãƒƒã‚¯ã‚’LLMå‘ã‘ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå½¢å¼ã«å¤‰æ›ã™ã‚‹ã€‚"""
    if not stack:
        context_str = "No current context (This is likely the beginning of the document)."
        depth = 0
    else:
        path_str = " > ".join([f"{'#' * h['level']} {h['title']}" for h in stack])
        depth = stack[-1]['level']
        context_str = f"Current Path: {path_str}\nCurrent Heading Depth: {depth}"

    prompt_context = f"""
--- DOCUMENT CONTEXT ---
You are currently inside the following document structure. Use this information to determine the correct heading levels (e.g., if current depth is 2, a new major heading on the page is likely level 3 '###').
{context_str}
--- END DOCUMENT CONTEXT ---
"""
    return prompt_context, depth

# --- æ—¢å­˜ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
def image_to_base64(image_path: str) -> str:
    try:
        with Image.open(image_path) as img:
            buffered = BytesIO(); img.convert('RGB').save(buffered, format="JPEG")
            return base64.b64encode(buffered.getvalue()).decode('utf-8')
    except Exception as e:
        print(f"âŒ ç”»åƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {image_path}, {e}"); return None

def call_llm(chat_model, prompt_text, b64_image):
    message = HumanMessage(content=[{"type": "text", "text": prompt_text}, {"type": "image_url", "image_url": f"data:image/jpeg;base64,{b64_image}"}])
    try:
        return chat_model.invoke([message]).content
    except Exception as e:
        print(f"âŒ Ollamaãƒ¢ãƒ‡ãƒ«å‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}"); return None

def analyze_page_structure(chat_model, image_path, cache_path, context_prompt):
    if os.path.exists(cache_path):
        print(f"ğŸ§  ã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆ©ç”¨: {os.path.basename(cache_path)}")
        with open(cache_path, 'r', encoding='utf-8') as f: return json.load(f).get("analysis_text")
    
    analysis_prompt = f"{SYSTEM_PROMPT}\n{context_prompt}\nAnalyze the layout... (ä»¥ä¸‹ã€å…ƒã®ANALYSIS_PROMPTã¨åŒæ§˜)" # ç°¡ç•¥åŒ–
    print(f"ğŸ”¬ ãƒšãƒ¼ã‚¸æ§‹é€ ã‚’è§£æä¸­: {os.path.basename(image_path)}")
    b64_image = image_to_base64(image_path)
    if not b64_image: return None
    analysis_text = call_llm(chat_model, analysis_prompt, b64_image)
    if analysis_text:
        with open(cache_path, 'w', encoding='utf-8') as f: json.dump({"analysis_text": analysis_text}, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ è§£æçµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {os.path.basename(cache_path)}")
    return analysis_text

# --- ä¸»è¦å‡¦ç†é–¢æ•° (ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¯¾å¿œç‰ˆ) ---

def run_basic_process(chat_model, files_to_process, state):
    print("\n--- ğŸš€ åŸºæœ¬å‡¦ç†ãƒ¢ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã™ ---")
    try:
        start_index = files_to_process.index(state['last_processed_page']) + 1 if state['last_processed_page'] in files_to_process else 0
    except ValueError: start_index = 0
    if start_index > 0: print(f"â–¶ï¸ å‰å›ã®å‡¦ç† '{state['last_processed_page']}' ã®æ¬¡ã‹ã‚‰å†é–‹ã—ã¾ã™ã€‚")

    files_to_run = files_to_process[start_index:]
    if not files_to_run: print("âœ… ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯æ—¢ã«å‡¦ç†æ¸ˆã¿ã®ã‚ˆã†ã§ã™ã€‚"); return

    for filename in files_to_run:
        print(f"\n--- ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ: {filename} ---")
        input_path = os.path.join(INPUT_DIR, filename)
        output_path = os.path.join(OUTPUT_DIR, os.path.splitext(filename)[0] + ".md")

        context_prompt_str, _ = format_context_for_prompt(state['heading_context_stack'])
        basic_prompt = f"{SYSTEM_PROMPT}\n{context_prompt_str}\nYour task is to transcribe the provided page... (ä»¥ä¸‹ã€å…ƒã®BASIC_EXTRACTION_PROMPTã¨åŒæ§˜)" # ç°¡ç•¥åŒ–
        
        print(f"ğŸ“„ åŸºæœ¬å‡¦ç†ä¸­: {filename}")
        b64_image = image_to_base64(input_path)
        if not b64_image: continue

        start_time = time.time()
        markdown_content = call_llm(chat_model, basic_prompt, b64_image)
        
        if markdown_content:
            with open(output_path, "w", encoding="utf-8") as f: f.write(markdown_content)
            print(f"âœ… æˆåŠŸ: {os.path.basename(output_path)} ã‚’ä½œæˆã—ã¾ã—ãŸã€‚({time.time() - start_time:.2f}ç§’)")
            state['heading_context_stack'] = update_heading_stack(state['heading_context_stack'], markdown_content)
            state['last_processed_page'] = filename
            save_document_state(state)
        else:
            print(f"âŒ å‡¦ç†å¤±æ•—: {filename}ã€‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚"); break

def run_refine_process(chat_model, refine_files, state):
    print("\n--- âœ¨ å†å‡¦ç†ï¼ˆãƒªãƒ•ã‚¡ã‚¤ãƒ³ï¼‰ãƒ¢ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã™ ---")
    print("âš ï¸ æ³¨æ„: ãƒªãƒ•ã‚¡ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰ã¯æ–‡æ›¸å…¨ä½“ã®çŠ¶æ…‹ã‚’æ›´æ–°ã—ã¾ã›ã‚“ã€‚")
    context_prompt_str, _ = format_context_for_prompt(state['heading_context_stack'])

    for filename in refine_files:
        print(f"\n--- ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ: {filename} ---")
        input_path = os.path.join(INPUT_DIR, filename)
        output_path = os.path.join(OUTPUT_DIR, os.path.splitext(filename)[0] + ".md")
        cache_path = os.path.join(CACHE_DIR, os.path.splitext(filename)[0] + ".json")

        analysis_text = analyze_page_structure(chat_model, input_path, cache_path, context_prompt_str)
        if not analysis_text: print(f"âŒ è§£æå¤±æ•—: {filename}"); continue

        print(f"âœï¸ é«˜ç²¾åº¦æŠ½å‡ºã‚’å®Ÿè¡Œä¸­: {filename}")
        b64_image = image_to_base64(input_path)
        if not b64_image: continue

        # REFINED_EXTRACTION_PROMPT_TEMPLATEã®å…ƒã€…ã®å†…å®¹ã‚’å†ç¾ã—ã¤ã¤ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒ¿å…¥
        refined_template = f"""{SYSTEM_PROMPT}
{context_prompt_str}
You will perform a highly accurate transcription of the provided page.
First, study this example:
--- EXAMPLE START ---
{PERFECT_EXAMPLE_MARKDOWN}
--- END EXAMPLE ---
Next, study this analysis:
--- ANALYSIS ---
{{analysis_text}}
--- END ANALYSIS ---
Considering both, transcribe the entire page.
"""
        final_prompt = refined_template.replace('{analysis_text}', analysis_text)
        
        start_time = time.time()
        markdown_content = call_llm(chat_model, final_prompt, b64_image)
        if markdown_content:
            with open(output_path, "w", encoding="utf-8") as f: f.write(markdown_content)
            print(f"âœ…âœ… æˆåŠŸ (å†å‡¦ç†): {os.path.basename(output_path)} ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚({time.time() - start_time:.2f}ç§’)")

def main():
    for dir_path in [OUTPUT_DIR, CACHE_DIR]:
        os.makedirs(dir_path, exist_ok=True)
        
    document_state = load_document_state()

    parser = argparse.ArgumentParser(description="HoTT Bookã®ãƒšãƒ¼ã‚¸ã‚’OCRå‡¦ç†ã—ã€Markdownã«å¤‰æ›ã—ã¾ã™ã€‚")
    parser.add_argument('--refine', nargs='+', metavar='FILENAME', help="æŒ‡å®šã—ãŸãƒ•ã‚¡ã‚¤ãƒ«åã«å¯¾ã—ã¦é«˜ç²¾åº¦ãªå†å‡¦ç†ï¼ˆãƒªãƒ•ã‚¡ã‚¤ãƒ³ï¼‰ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
    args = parser.parse_args()

    print(f"ğŸ¤– Ollama ({OLLAMA_MODEL}ãƒ¢ãƒ‡ãƒ«) ã‚’åˆæœŸåŒ–ã—ã¾ã™...")
    try:
        chat = ChatOllama(model=OLLAMA_MODEL, temperature=0.1)
    except Exception as e:
        print(f"âŒ Ollamaãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: {e}"); return

    if args.refine:
        run_refine_process(chat, args.refine, document_state)
    else:
        try:
            all_files = sorted([f for f in os.listdir(INPUT_DIR) if f.startswith("page-") and f.lower().endswith(".jpg")])
            run_basic_process(chat, all_files, document_state)
        except FileNotFoundError:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{INPUT_DIR}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

    print("\n--- ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ ---")

if __name__ == "__main__":
    main()
